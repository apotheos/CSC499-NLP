Chapter 7, Exercise 13
======================

> Pick one of the three chunk types in the CoNLL Chunking Corpus. Write functions
>  to do the following tasks for your chosen type:
>
>  1. List all the tag sequences that occur with each instance of this chunk type.
>  2. Count the frequency of each tag sequence, and produce a ranked list in order
>     of decreasing frequency; each line should consist of an integer (the frequency)
>     and the tag sequence.
>  3. Inspect the high-frequency tag sequences. Use these as the basis for developing
>     a better chunker.

Parts 1 and 2
-------------

To accomplish this, I wrote a function np_tags_fd that takes a list of (word, tag, chunk) tuples
and transforms them into a frequency distribution of tag tuples, where each tag tuple represents
a single chunk. Once these data are in a frequency distribution, it's trivial to print a list
with FreqDist.keys(), so Part 1 is done.

Part II asks for the frequencies printed alongside the tags in descending order of frequency. This
is also trivial to do once you have a frequency distribution, but the results are important for
Part III, so I have included the 50 most frequent results below, printed in alphabetical order:

```
0.4791% 	('$', 'CD')
1.5347% 	('$', 'CD', 'CD')
0.3598% 	('$', 'CD', 'DT', 'NN')
1.6182% 	('CD',)
0.3678% 	('CD', 'CD')
1.3896% 	('CD', 'NN')
0.8688% 	('CD', 'NNS')
0.2942% 	('CD', 'NNS', 'DT', 'NN')
0.9125% 	('DT',)
0.2207% 	('DT', 'CD', 'NNS')
0.3419% 	('DT', 'JJ', 'JJ', 'NN')
3.8388% 	('DT', 'JJ', 'NN')
0.5109% 	('DT', 'JJ', 'NN', 'NN')
0.4871% 	('DT', 'JJ', 'NNS')
11.5522% 	('DT', 'NN')
1.6779% 	('DT', 'NN', 'NN')
0.2863% 	('DT', 'NN', 'NNS')
0.2863% 	('DT', 'NN', 'POS', 'NN')
0.8071% 	('DT', 'NNP')
0.7157% 	('DT', 'NNP', 'NN')
0.5527% 	('DT', 'NNP', 'NNP')
0.2783% 	('DT', 'NNP', 'NNP', 'NNP')
2.0874% 	('DT', 'NNS')
0.2644% 	('DT', 'VBN', 'NN')
0.3559% 	('EX',)
0.2783% 	('JJ', 'JJ', 'NN')
0.2823% 	('JJ', 'JJ', 'NNS')
1.8965% 	('JJ', 'NN')
0.2187% 	('JJ', 'NN', 'NN')
0.6004% 	('JJ', 'NN', 'NNS')
3.2245% 	('JJ', 'NNS')
5.7214% 	('NN',)
0.8886% 	('NN', 'NN')
1.9164% 	('NN', 'NNS')
4.9123% 	('NNP',)
0.3101% 	('NNP', 'CD')
0.2127% 	('NNP', 'NN')
4.6002% 	('NNP', 'NNP')
1.2465% 	('NNP', 'NNP', 'NNP')
0.4215% 	('NNP', 'NNP', 'NNP', 'NNP')
0.3320% 	('NNP', 'NNS')
0.2684% 	('NNP', 'POS', 'NN')
5.9103% 	('NNS',)
6.7154% 	('PRP',)
0.3797% 	('PRP$', 'JJ', 'NN')
1.1391% 	('PRP$', 'NN')
0.2068% 	('PRP$', 'NN', 'NN')
0.6580% 	('PRP$', 'NNS')
0.7892% 	('WDT',)
0.4095% 	('WP',)
```

Part 3
------

I started with the fairly successful RegexpParser from the book with pattern `NP: {<[CDJNP].*>+}`:

```
ChunkParse score:
    IOB Accuracy:  87.7%
    Precision:     70.6%
    Recall:        67.8%
    F-Measure:     69.2%
```

Looking at the list from part 2, I noticed that this tagger was not tagging noun phrases in the beginning
of a sentence. So, I added it to the pattern, making `NP: {<\$>?<[CDJNP].*>+}`. There is a significant
improvement in the results:

```
ChunkParse score:
    IOB Accuracy:  89.1%
    Precision:     72.2%
    Recall:        69.4%
    F-Measure:     70.8%
```

Finally, I identified that WDT and WP are tagged as noun phrases when they occur by themselves, so I added
a pattern `{<W(P|DT)>}` to the regular expression. This also caused an improvement:

```
ChunkParse score:
    IOB Accuracy:  89.7%
    Precision:     72.9%
    Recall:        71.9%
    F-Measure:     72.4%
```

That was about all I could do with the 50 most frequent patterns above, so I scanned through
the 200 most frequent and tried some things from there, but they did not improve my results.
This is likely because some strings of tags might be ambiguous as to which chunks they belong
to. Overall, this method yielded ~3% increase in each of the statistics, which is a sizable
improvement.
