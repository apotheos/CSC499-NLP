Identifying Languages with the Spearman Correlation and NLTK
============================================================

The problem below is taken from Chapter 3 of *[Natural Language Processing with Python](http://nltk.org/book)*. 

> 43\. With the help of a multilingual corpus such as the Universal Declaration of Human Rights Corpus
  (`nltk.corpus.udhr`), along with NLTK's frequency distribution and rank correlation functionality
  (`nltk.FreqDist`, `nltk.spearman_correlation`), develop a system that guesses the language of a
  previously unseen text. For simplicity, work with a single character encoding and just a few languages.

See [CSC499-NLP/ch_3/exercises/languages_guessing.py](https://github.com/apotheos/CSC499-NLP/blob/master/ch_3/exercises/language_guessing.py) for code.

So, with the problem in mind I decided to make it harder for myself by ignoring the authors' suggestions in the last
sentence above. Namely, I work with Latin-1 and UTF-8, which allows me to use a large percentage of the UDHR corpus.

First I need to figure out what the Spearman correlation is. From Wikipedia:

> In statistics, Spearman's rank correlation coefficient or Spearman's rho, named after Charles Spearman and often denoted by the Greek letter \rho (rho) or as r_s, is a nonparametric measure of statistical dependence between two variables. It assesses how well the relationship between two variables can be described using a monotonic function. If there are no repeated data values, a perfect Spearman correlation of +1 or âˆ’1 occurs when each of the variables is a perfect monotone function of the other.

And from NLTK's documentation on the `spearman_correlation(rank1, rank2)` function:

> Returns the Spearman correlation coefficient for two rankings, which
  should be dicts or sequences of (key, rank). The coefficient ranges from
  -1.0 (ranks are opposite) to 1.0 (ranks are identical), and is only
  calculated for keys in both rankings (for meaningful results, remove keys
  present in only one list before ranking).

From these bits of information it is clear that the Spearman correlation takes two ordered rankings calculates how
different they are from one another. A ranking is basically a frequency distribution with the "count" replaced with a rank
showing how often a word occurs in a text relative to the other words. This means I can store each training set and the
sample data as `FreqDist`s right until I actually use the `spearman_correlation(r1, r2)` function.

I also noted the last parenthetical of the NLTK documentation: "for meaningful results, remove keys present in only one
list before ranking". I'll revisit that later, though.

Making the Training Set(s)
--------------------------

First I need to create FreqDists for each text in the UDHR Corpus and place them in a map of {"language": FreqDist}.
This bit of preprocessing allows me to easily calculate and compare ranks for sample texts of unknown languages. I can
accomplish this by looping through each file id (each file is a different language), and making a frequency distribution
out of it:

```python
result[language] = FreqDist(udhr.words(_id))
```

In the above code, assume `_id` has been previously initialized with one of the file names in the UDHR corpus,
`language` with the a string representing the language the file contains, and `result` is a dictionary that maps
language strings to `FreqDist`s.
